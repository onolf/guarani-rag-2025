# üáµüáæ guarani-rag-2025

# üìù Generaci√≥n de Texto Sint√©tico en Guaran√≠ mediante Transformaciones Gramaticales

**Comparativa: LLM Prompting (sin RAG) vs. Sistema RAG**  
Diplomado en NLP & IA ‚Äì FPUNA 2025

## üßë‚Äçüíª Integrante
- Odil√≥n Nolf S√°nchez

## üéØ Objetivo del Proyecto

Desarrollar y comparar dos agentes conversacionales capaces de generar texto sint√©tico en guaran√≠ aplicando transformaciones gramaticales espec√≠ficas (tiempo verbal, persona, nasalizaci√≥n, posesivos, etc.):

1. **Chatbot sin RAG**: Implementaci√≥n basada √∫nicamente en *prompting* utilizando los modelos `google/gemma-3-27b` y `meta-llama/llama-3.3-70b-instruct`.
2. **Chatbot con RAG**: Implementaci√≥n que utiliza la **Recuperaci√≥n Aumentada por Generaci√≥n (RAG)**, recuperando fragmentos del Diccionario y Gram√°tica Guaran√≠ mediante **FAISS**.

## üìÇ Estructura del Repositorio
```text
.
‚îú‚îÄ‚îÄ guarani_pln_2025.ipynb          ‚Üê Entrega oficial
‚îú‚îÄ‚îÄ README.md                       ‚Üê Archivo de instrucciones
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ Diccionario_Guarani-Espanol.pdf
‚îÇ   ‚îî‚îÄ‚îÄ Gramatica_guarani.pdf
‚îú‚îÄ‚îÄ no_rag_chatbot/                 ‚Üê Agente solo prompting
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îî‚îÄ‚îÄ chainlit.md
‚îî‚îÄ‚îÄ rag_chatbot/                    ‚Üê Agente con RAG + FAISS
    ‚îú‚îÄ‚îÄ app.py
    ‚îî‚îÄ‚îÄ chainlit.md
```

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n
```bash
git clone https://github.com/onolf/guarani-rag-2025.git
cd guarani-rag-2025
pip install -r requirements.txt

# Chatbot sin RAG
chainlit run no_rag_chatbot/app.py -w

# Chatbot con RAG
chainlit run rag_chatbot/app.py -w
```

## üß† Configuraci√≥n de Modelos (OpenRouter)

Ambos chatbots acceden a los siguientes modelos a trav√©s de OpenRouter:

* `meta-llama/llama-3.3-70b-instruct:free`
* `google/gemma-3-27b-it:free`

### üîë Configuraci√≥n de la API Key

Para la ejecuci√≥n, necesitas tu API key de OpenRouter. Esta debe ser cargada en la variable de entorno `OPENROUTER_API_KEY`.

**M√©todo Recomendado (.env):**

Para cargar la clave de forma segura, crea un archivo en la ra√≠z del repositorio llamado **`.env`** con el siguiente contenido (reemplazando el marcador de posici√≥n):
```text
OPENROUTER_API_KEY="[tu_api_key_de_openrouter]"
```

---

# üìä Resumen del Notebook de Entrega Oficial

## `guarani_pln_2025.ipynb`: Generaci√≥n de Texto Sint√©tico en Guaran√≠ mediante Transformaciones Gramaticales

### Comparativa: LLM Prompting (sin RAG) vs. Sistema RAG

Este repositorio contiene el proyecto final para el Diplomado en NLP & IA ‚Äì FPUNA 2025, centrado en la generaci√≥n de texto sint√©tico en guaran√≠ con transformaciones gramaticales precisas.

### 1. Entendimiento del Negocio

*   **Necesidad:** Generar texto sint√©tico en guaran√≠ aplicando transformaciones gramaticales (tiempos verbales, persona, nasalizaci√≥n, posesivos) para la preservaci√≥n ling√º√≠stica y la educaci√≥n.
*   **Problema:** Escasez de recursos digitales en guaran√≠, lo que lleva a "alucinaciones" (errores gramaticales o invenciones) en LLMs puros.
*   **Soluci√≥n Propuesta:** Implementar una arquitectura RAG (Retrieval-Augmented Generation) utilizando documentos gramaticales y diccionarios oficiales para fundamentar las respuestas del modelo.

### 2. Entendimiento y Preparaci√≥n de los Datos

*   **Fuentes de Datos:**
    *   Diccionario Guaran√≠-Espa√±ol (PDF).
    *   Gram√°tica Guaran√≠ (PDF).
*   **Preprocesamiento:**
    *   **Limpieza de Texto:** Eliminaci√≥n de ruido de PDFs (n√∫meros de p√°gina, encabezados repetitivos).
    *   **Chunking:** Divisi√≥n de documentos en fragmentos (`chunk_size=1000`, `chunk_overlap=200`).
    *   **Embedding:** Uso del modelo `sentence-transformers/all-MiniLM-L6-v2` para transformar el texto en vectores num√©ricos.
    *   **Vector Store:** Indexaci√≥n de los embeddings en FAISS para una b√∫squeda eficiente.

### 3. Metodolog√≠a y Aplicaci√≥n de Modelos

Se compararon dos estrategias para la generaci√≥n de texto:

1.  **Modelo Base (Sin RAG):** Pregunta directa a un LLM, bas√°ndose √∫nicamente en su conocimiento param√©trico.
2.  **Sistema RAG:** Recuperaci√≥n de contexto relevante del `Vector Store` seguido de la generaci√≥n por el LLM.

**Modelos de Lenguaje (LLMs) utilizados (v√≠a OpenRouter):**

*   **Llama 3.3** (`meta-llama/llama-3.3-70b-instruct:free`): Modelo de gran escala, como referencia de alta capacidad.
*   **Gemma 3** (`google/gemma-3-27b-it:free`): Modelo de menor escala, para evaluar escenarios de restricci√≥n computacional.

### 4. Evaluaci√≥n Cuantitativa

Se evaluaron cuatro configuraciones (Llama 3.3 sin RAG, Llama 3.3 con RAG, Gemma 3 sin RAG, Gemma 3 con RAG) sobre 7 ejemplos representativos del dataset `AmericasNLP` (guarani-dev.tsv).

*   **M√©tricas:**
    *   **chrF:** Adecuado para lenguas aglutinantes como el guaran√≠, mide similitud a nivel de caracteres.
    *   **Latencia:** Tiempo de respuesta en segundos.

*   **Resultados Clave (Promedios):**

| Modelo              | chrF Promedio | Latencia Promedio (s) |
|---------------------|---------------|------------------------|
| Gemma 3 CON RAG     | 36.50         | 1.00                   |
| Gemma 3 SIN RAG     | 33.95         | 0.97                   |
| LLaMA 3.3 CON RAG   | 52.78         | 1.80                   |
| LLaMA 3.3 SIN RAG   | 49.59         | 1.57                   |

*   **An√°lisis:**
    *   La incorporaci√≥n de **RAG mejor√≥ el puntaje chrF** en ambos modelos de forma consistente, con incrementos de aproximadamente 3 puntos para LLaMA 3.3 y 2.55 puntos para Gemma 3.
    *   **LLaMA 3.3 (Con RAG)** obtuvo el mejor desempe√±o (chrF: 52.78), indicando que el contexto gramatical recuperado complementa efectivamente el conocimiento param√©trico del modelo.
    *   El incremento en latencia fue marginal (0.03-0.23s), justificado por las ganancias en precisi√≥n.
    *   Los resultados validan que RAG proporciona referencias estructurales √∫tiles para transformaciones morfosint√°cticas en guaran√≠.

### 5. An√°lisis Cualitativo (Evaluaci√≥n Manual de Chatbots)

Se realiz√≥ una evaluaci√≥n manual de las 4 configuraciones en 10 ejemplos para fen√≥menos gramaticales espec√≠ficos (futuro, nasalizaci√≥n, posesivos).

*   **Resultados Clave (Aciertos / 10 ejemplos):**

| Prueba                    | Llama_NoRAG | Llama_RAG | Gemma_NoRAG | Gemma_RAG |
|---------------------------|-------------|-----------|-------------|-----------|
| Futuro 'che aha'          | 1/10        | 2/10      | 2/10        | 1/10      |
| Nasalizaci√≥n 'o√±embo'e'   | 0/10        | 3/10      | 1/10        | 2/10      |
| Posesivos 'r√≥ga'          | 2/10        | 4/10      | 4/10        | 3/10      |
| **Promedio**              | **1/10**    | **3/10**  | **2/10**    | **2/10**  |

*   **An√°lisis:**
    *   El an√°lisis cualitativo muestra que RAG mejora la **correcci√≥n gramatical percibida por humanos** en fen√≥menos complejos, especialmente para LLaMA 3.3 (incremento de 1/10 a 3/10).
    *   Para Gemma 3, el impacto fue m√°s moderado pero consistente.
    *   Esto complementa la evaluaci√≥n cuantitativa, confirmando que RAG aporta valor tanto en m√©tricas autom√°ticas como en correcci√≥n ling√º√≠stica funcional.

### 6. Aplicaci√≥n de KMEANS (An√°lisis del Espacio de Embeddings)

*   **Metodolog√≠a:** Aplicaci√≥n de K-Means (k=2 a 5) en los embeddings del RAG, con y sin normalizaci√≥n, y c√°lculo del Silhouette Score.
*   **Resultados:** Silhouette Scores entre 0.06 y 0.11, indicando una estructura sem√°ntica d√©bil pero consistente.
*   **An√°lisis:** Los embeddings normalizados se desempe√±aron mejor con k=2, mientras que los sin normalizar con k=3. A pesar de esta d√©bil separaci√≥n sem√°ntica, el sistema RAG logra recuperar contextos suficientemente relevantes que aportan informaci√≥n morfosint√°ctica √∫til, como evidencian las mejoras consistentes en chrF.

### 7. Conclusi√≥n Final

La evaluaci√≥n cuantitativa con chrF demostr√≥ que la incorporaci√≥n de RAG mejora consistentemente el desempe√±o en transformaciones gramaticales del guaran√≠, con LLaMA 3.3 alcanzando el mejor resultado (chrF: 52.78 con RAG vs. 49.59 sin RAG). El an√°lisis cualitativo confirm√≥ que RAG tambi√©n mejora la correcci√≥n ling√º√≠stica percibida por humanos en fen√≥menos complejos como la nasalizaci√≥n y construcciones posesivas. 

Los resultados validan que el acceso a ejemplos espec√≠ficos y patrones gramaticales relevantes complementa efectivamente las capacidades generativas de los modelos base, proporcionando referencias estructurales que facilitan transformaciones morfosint√°cticas m√°s precisas. El incremento marginal en latencia resulta justificado frente a las ganancias en precisi√≥n obtenidas.

**Limitaciones:** Se utilizaron dos API keys de OpenRouter para procesar 7 registros representativos del conjunto DEV de AmericasNLP en las cuatro configuraciones evaluadas, generando un total de 28 registros procesados. Las restricciones de cuota en la versi√≥n gratuita de OpenRouter (50 llamadas diarias) y las incompatibilidades con el sistema de cr√©ditos de pago limitaron significativamente el alcance de la evaluaci√≥n cuantitativa, impactando en la representatividad estad√≠stica de los resultados.